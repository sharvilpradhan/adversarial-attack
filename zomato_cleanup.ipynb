{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "X11w8QLmf9Ha",
    "outputId": "bab87c6f-fb3f-42e2-b2f7-758891cba03f"
   },
   "outputs": [],
   "source": [
    "print(\"Importing the modules...\")\n",
    "# Importing the required modules\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('word_tokenize')\n",
    "nltk.download('words')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "import pandas as pd\n",
    "import re\n",
    "# to check for valid english words\n",
    "from nltk.corpus import words\n",
    "# for the vector creation\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "# to import the document\n",
    "import io\n",
    "# to detect the Mojibake strings\n",
    "!pip install ftfy\n",
    "import ftfy\n",
    "from ftfy.badness import sequence_weirdness\n",
    "# to detect the NaN (not a number) values in the csv\n",
    "import math\n",
    "nltk.download(\"punkt\")\n",
    "# Abstract Syntax Trees. A better alternative to the regex.\n",
    "import ast\n",
    "import time\n",
    "# for a beep after running is over\n",
    "# import winsound\n",
    "\n",
    "frequency = 750  # 2500 Hz\n",
    "duration = 500  # 1 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZfhxDEf2ijD"
   },
   "outputs": [],
   "source": [
    "# Trying Pydrive\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEXCakyq27Ux"
   },
   "outputs": [],
   "source": [
    "# Main data file\n",
    "link = \"https://drive.google.com/open?id=1SMbOzDeQv8feCe8xnCCsXy210wund7V7\"\n",
    "# Sample data file\n",
    "# link = \"https://drive.google.com/open?id=1pViZwQKuD6WHP8BKfPCycZI2cFg5_Hi0\"\n",
    "fluff, id = link.split('=')\n",
    "# print (id) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQEv4Yql2_6O"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('zomato.csv')  \n",
    "zomato = pd.read_csv('zomato.csv')\n",
    "reviews = zomato['reviews_list']\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input csv file\n",
    "zomato = pd.read_csv('zomato.csv')\n",
    "reviews = zomato['reviews_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0um7yEJ7Elb5"
   },
   "outputs": [],
   "source": [
    "# # checking the output\n",
    "for i in reviews[0:10]:\n",
    "    print(i)\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KI1Wez0YiYIo"
   },
   "outputs": [],
   "source": [
    "def processData(reviews):\n",
    "    print(\"Diving the multiple reviews in the single cell...\")\n",
    "    # Dividing the multiple reviews in the single cell\n",
    "    # individualReviews = []\n",
    "    reviewBlocks = []\n",
    "    # print(len(reviews))\n",
    "    # print(math.isnan(reviews[0]))\n",
    "    # reviews = reviews[0:6]\n",
    "    # print(reviews)\n",
    "    # reviewsFiltered = (i for i in reviews if i is not None)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # print(reviews[0])\n",
    "    print(\"Removing the empty cells...\")\n",
    "    for i in reviews:\n",
    "        # print(reviews)\n",
    "        if i == \"[]\" or None:\n",
    "            # print(reviews[i])\n",
    "            # this is used when reviews is the whole data\n",
    "            # reviews[i] = \"garbage_value\"\n",
    "            # this is used when being sent in partition\n",
    "            return None\n",
    "            # reviews.remove(i)\n",
    "            # print(reviews[i])\n",
    "        try:\n",
    "            if math.isnan(i):\n",
    "            # print(reviews[i])\n",
    "            # This is for collective input\n",
    "                # reviews[i] = \"garbage_value\"\n",
    "            # This is for single input\n",
    "                return None\n",
    "            # This is for 2 inputs\n",
    "                # reviews.remove(i)\n",
    "        except TypeError:\n",
    "            continue\n",
    "    print(\"Dividing the reviews...\")\n",
    "\n",
    "    for eachRestaurantReview in reviews:\n",
    "        \"\"\"1.1 eachRestaurant has all the reviews of one restaurant each \"\"\"\n",
    "        try:\n",
    "            reviewBlocks = reviewBlocks + [list(x) if isinstance(x, tuple) else [x] for x in ast.literal_eval(eachRestaurantReview)]\n",
    "        except ValueError:\n",
    "            continue\n",
    "    # --------------------------------------------------------\n",
    "    filteredBlocksDivided = reviewBlocks\n",
    "\n",
    "    # removing the keywords RATED and Rated\n",
    "    for rBlock in filteredBlocksDivided:\n",
    "        # print(rBlock)\n",
    "        # This is because some of the reviews do no contain of the these. So, ignoring those.\n",
    "        if rBlock[0] == None or rBlock[1] == None:\n",
    "            filteredBlocksDivided.remove(rBlock)\n",
    "            # Using continue will skip the rest of the iteration to start the next iteration\n",
    "            continue\n",
    "        rBlock[0] = rBlock[0].replace(\"Rated\",\"\")\n",
    "        rBlock[0] = float(rBlock[0])\n",
    "        # Removing only the first instance of the occurance of RATED in the review\n",
    "        rBlock[1] = rBlock[1].replace(\"RATED\",\"\",1)\n",
    "        rBlock[1] = rBlock[1].replace(\"\\n\", \"\").strip()\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Collecting the set of stop words...\")\n",
    "    # Collecting the set of stop words\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    \"\"\"1.6 Filtering the review comments of any stop words. (Ignoring the 1.4)\"\"\"\n",
    "    \"\"\"1.7 Conducting extra filtering, removing the punctuations that's not covered in 1.6\"\"\"\n",
    "\n",
    "    # The punctuationExtra is for the 1.7\n",
    "    punctuationExtra = [\".\", \",\", \"''\", \"``\", \"(\", \")\", \":\", \";\", \"{\", \"}\", \"[\", \"]\", \"!\", \"~\", \"`\", \"?\", \"'\", \"/\"]\n",
    "    numbers = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "    punctuationExtra = punctuationExtra + numbers\n",
    "    # print(filteredBlocksDivided)\n",
    "    # ---------------------------------------------------------------\n",
    "    # To check the immediate duplicates. Ignoring the duplicates or else.\n",
    "    reviewTokensOld = []\n",
    "    # has all the review only in tokens\n",
    "    reviewTokensFinal = []\n",
    "\n",
    "    for review in filteredBlocksDivided:\n",
    "        # Duplicate entries in the reviews. Getting rid of the them. \"set\" won't work as list is hashable - mutable (here)\n",
    "        # print(review)\n",
    "        # comment has the tokenized review[1] and review[0] is the rating\n",
    "        # adding space after these to get good tokens\n",
    "        review[1] = review[1].replace(\".\", \" . \")\n",
    "        review[1] = review[1].replace(\"'\", \" ' \")\n",
    "        review[1] = review[1].replace(\"/\", \" \")\n",
    "        # it's a waste to keep \\\\n still lying around\n",
    "        review[1] = review[1].replace(\"\\\\n\", \"\")\n",
    "        reviewTokensNow = word_tokenize(review[1].lower())\n",
    "        if reviewTokensNow == reviewTokensOld:\n",
    "            # found a duplicate! Don't think have to remove as under because won't use it anyway\n",
    "            filteredBlocksDivided.remove(review)\n",
    "            continue\n",
    "        else:\n",
    "            # if not a duplicate then go on with the process\n",
    "            # print(reviewTokens)\n",
    "            # removing the stopwords\n",
    "            # 1.6 being realised\n",
    "            reviewTokensFiltered = [i for i in reviewTokensNow if i not in stopWords]\n",
    "            # print(reviewTokensFiltered)\n",
    "            # 1.7 being realised\n",
    "            reviewTokensFurtherFiltered = [i for i in reviewTokensFiltered if i not in punctuationExtra]\n",
    "            # print(reviewTokensFurtherFiltered)\n",
    "            problemFlag = False\n",
    "            # checking if these are corrupted i.e. valid english words - including variations - PROBLEM!!!\n",
    "            for i in range(0, len(reviewTokensFurtherFiltered)):  # Most of them are variations - PROBLEM!!!\n",
    "                # if reviewTokensFurtherFiltered[i] not in words.words():\n",
    "                # Need to check the threshold later but for now putting it to be 0\n",
    "                if sequence_weirdness(reviewTokensFurtherFiltered[i])> 0:\n",
    "                    # found one garbage! Don't think have to remove as under because won't use it anyway\n",
    "                    # filteredBlocksDivided.remove(review)\n",
    "                    # print(reviewTokensFurtherFiltered[i])\n",
    "                    problemFlag = True\n",
    "                    break\n",
    "                    # i = i+1\n",
    "                # else:\n",
    "                    # reviewTokensFinal = reviewTokensFinal + [reviewTokensFurtherFiltered]\n",
    "            \n",
    "            if not problemFlag:\n",
    "            # tempSentence = \" \".join([])\n",
    "                reviewTokensFinal.append([review[0],\" \".join(reviewTokensFurtherFiltered)])\n",
    "        # updating to check later for duplicates\n",
    "        reviewTokensOldOld = reviewTokensNow\n",
    "\n",
    "    return reviewTokensFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Oi8jukgcoMzR",
    "outputId": "aee7b017-28b9-4378-c8c3-2ace37e9ada0"
   },
   "outputs": [],
   "source": [
    "# USE THIS TO PROCESS THE ENTIRE DATA!!!\n",
    "\n",
    "startTime = time.time()\n",
    "reviewTokensFinal = []\n",
    "print(\"The total number of restaurants to be processed = \" + str(len(reviews)))\n",
    "# This variable is to just keep track of the processing. No particular importance.\n",
    "temp = 0\n",
    "for i in reviews:\n",
    "    print(\"Index = \" + str(temp))\n",
    "#     Arguments in the form of a list because the function is processing the lists not just the strings. 'i' is a string.\n",
    "    processedReview = processData([i])\n",
    "    if processedReview is not None:\n",
    "        reviewTokensFinal = reviewTokensFinal + processedReview\n",
    "    temp = temp + 1\n",
    "\n",
    "print(\"All Done!\")\n",
    "print(\"--------%s seconds--------------\" %(time.time()-startTime))\n",
    "print(\"Number of reviews: \" + str(len(reviewTokensFinal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_Wc0TgTXvR0"
   },
   "outputs": [],
   "source": [
    "# Removing the duplicates\n",
    "startTime = time.time()\n",
    "reviewTokensFinal2 = []\n",
    "for i in reviewTokensFinal:\n",
    "    if i not in reviewTokensFinal2 and i not \"Nan\":\n",
    "        reviewTokensFinal2.append(i)\n",
    "        \n",
    "print(\"----------%s seconds------------\" %(time.time()-startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are empty reviews as well.\n",
    "for i in reviewTokensFinal2:\n",
    "    if i[1] == \"Nan\":\n",
    "        print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTaMPFzK5fxO"
   },
   "outputs": [],
   "source": [
    "# Make a sound after done\n",
    "# winsound.Beep(frequency, duration)\n",
    "# Use this when using in Jupyter Notebooks\n",
    "import csv\n",
    "# reviewTokensFinal = list(set(reviewTokensFinal2))\n",
    "# using utf-8 encoding here as there was an error regarding the encoding\n",
    "with open('processedZomato_fullFinal.csv','w', newline = '', encoding = 'utf-8') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(reviewTokensFinal2)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpZongQtN_pU"
   },
   "outputs": [],
   "source": [
    "# Use this when using in Google colab\n",
    "from google.colab import files\n",
    "files.download('processedZomato_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1U1H18GcbKSW"
   },
   "outputs": [],
   "source": [
    "print(len(reviewTokensFinal2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ALDA_Project_v2.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
